#!/bin/bash

# ML API Production Deployment Script
# This script helps deploy the ML API to production

echo "üöÄ ML API Production Deployment Guide"
echo "======================================"
echo ""

# Check if we're in the right directory
if [ ! -f "ml_api.py" ]; then
    echo "‚ùå Error: ml_api.py not found. Please run this script from the scripts/ directory."
    exit 1
fi

echo "üìã Prerequisites Check:"
echo "1. Ensure you have access to your production server (mfldata.com)"
echo "2. Ensure port 8000 is open and accessible"
echo "3. Ensure Python 3.8+ is installed on the server"
echo ""

echo "üîß Deployment Options:"
echo ""
echo "Option 1: Manual Server Deployment"
echo "----------------------------------"
echo "1. Upload these files to your production server:"
echo "   - scripts/ml_api.py"
echo "   - scripts/requirements.txt"
echo "   - models/ (entire directory with .pkl files)"
echo ""
echo "2. SSH into your production server and run:"
echo "   cd /path/to/uploaded/files"
echo "   pip3 install -r requirements.txt"
echo "   python3 ml_api.py"
echo ""
echo "Option 2: Docker Deployment (Recommended)"
echo "----------------------------------------"
echo "1. Create a Dockerfile on your production server:"
echo "   FROM python:3.9-slim"
echo "   WORKDIR /app"
echo "   COPY requirements.txt ."
echo "   RUN pip install -r requirements.txt"
echo "   COPY ml_api.py ."
echo "   COPY models/ ./models/"
echo "   EXPOSE 8000"
echo "   CMD [\"python3\", \"ml_api.py\"]"
echo ""
echo "2. Build and run:"
echo "   docker build -t ml-api ."
echo "   docker run -d -p 8000:8000 --name ml-api-container ml-api"
echo ""
echo "Option 3: Systemd Service (For persistent deployment)"
echo "----------------------------------------------------"
echo "1. Create /etc/systemd/system/ml-api.service:"
echo "   [Unit]"
echo "   Description=ML API Service"
echo "   After=network.target"
echo ""
echo "   [Service]"
echo "   Type=simple"
echo "   User=www-data"
echo "   WorkingDirectory=/var/www/ml-api"
echo "   ExecStart=/usr/bin/python3 ml_api.py"
echo "   Restart=always"
echo ""
echo "   [Install]"
echo "   WantedBy=multi-user.target"
echo ""
echo "2. Enable and start the service:"
echo "   sudo systemctl enable ml-api"
echo "   sudo systemctl start ml-api"
echo ""

echo "üåê Domain Configuration:"
echo "Ensure your domain mfldata.com is configured to route port 8000 traffic to your ML API server."
echo ""

echo "üîç Verification Steps:"
echo "1. Test the health endpoint:"
echo "   curl https://mfldata.com:8000/health"
echo ""
echo "2. Test a prediction:"
echo "   curl -X POST https://mfldata.com:8000/predict \\"
echo "     -H \"Content-Type: application/json\" \\"
echo "     -d '{\"attributes\":{\"PAC\":84,\"SHO\":32,\"PAS\":77,\"DRI\":74,\"DEF\":87,\"PHY\":83},\"positions\":[\"LB\"]}'"
echo ""

echo "üìù Environment Variables for Production:"
echo "Set these on your production server:"
echo "export ML_API_HOST=\"0.0.0.0\""
echo "export ML_API_PORT=\"8000\""
echo ""

echo "üîí Security Considerations:"
echo "- Consider using HTTPS for the API"
echo "- Restrict CORS origins to your domain"
echo "- Use a reverse proxy (nginx) for better security"
echo "- Monitor API usage and logs"
echo ""

echo "‚úÖ Deployment Complete!"
echo "Your ML API should now be accessible at: https://mfldata.com:8000"
